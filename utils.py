import pandas as pd
import numpy as np
import streamlit as st
from typing import Tuple, List, Optional, Union
import logging
from datetime import datetime

def setup_logging():
    """ë¡œê¹… ì„¤ì •"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    return logging.getLogger(__name__)

logger = setup_logging()

def validate_dataframe(df: pd.DataFrame, ticker: str, required_columns: List[str]) -> bool:
    """ë°ì´í„°í”„ë ˆì„ ìœ íš¨ì„± ê²€ì‚¬"""
    if df is None:
        st.error(f"'{ticker}' ë°ì´í„°ê°€ Noneì…ë‹ˆë‹¤.")
        return False
        
    if df.empty:
        st.error(f"'{ticker}' ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.")
        return False
    
    missing_columns = [col for col in required_columns if col not in df.columns]
    if missing_columns:
        st.error(f"í•„ìˆ˜ ì»¬ëŸ¼ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤: {missing_columns}")
        return False
    
    if not isinstance(df.index, pd.DatetimeIndex):
        st.error(f"'{ticker}' ë°ì´í„°ì˜ ì¸ë±ìŠ¤ê°€ ë‚ ì§œ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤. (í˜„ì¬ íƒ€ì…: {type(df.index)})")
        return False
    
    # ë°ì´í„° í’ˆì§ˆ ê²€ì‚¬
    null_counts = df[required_columns].isnull().sum()
    if null_counts.any():
        st.warning(f"'{ticker}' ë°ì´í„°ì— ê²°ì¸¡ê°’ì´ ìˆìŠµë‹ˆë‹¤: {null_counts[null_counts > 0].to_dict()}")
    
    # ìµœì†Œ ë°ì´í„° ê°œìˆ˜ í™•ì¸
    if len(df) < 50:
        st.error(f"'{ticker}' ë°ì´í„°ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤. (í˜„ì¬: {len(df)}ê°œ, ìµœì†Œ í•„ìš”: 50ê°œ)")
        return False
    
    return True

def normalize_timezone(df: pd.DataFrame, target_tz: str = 'Asia/Seoul') -> pd.DataFrame:
    """íƒ€ì„ì¡´ ì •ê·œí™”"""
    try:
        if df.index.tz is None:
            df.index = df.index.tz_localize('UTC').tz_convert(target_tz)
        else:
            df.index = df.index.tz_convert(target_tz)
        return df
    except Exception as e:
        logger.warning(f"íƒ€ì„ì¡´ ì •ê·œí™” ì‹¤íŒ¨: {e}")
        return df

def clean_data(df: pd.DataFrame, required_columns: List[str]) -> pd.DataFrame:
    """ë°ì´í„° ì •ë¦¬ ë° ì „ì²˜ë¦¬"""
    df_clean = df.copy()
    
    # ê²°ì¸¡ê°’ ì²˜ë¦¬ (forward fill í›„ backward fill)
    df_clean[required_columns] = df_clean[required_columns].fillna(method='ffill').fillna(method='bfill')
    
    # ì´ìƒê°’ ì²˜ë¦¬ (ê° ì»¬ëŸ¼ë³„ë¡œ 99.5% ë¶„ìœ„ìˆ˜ë¡œ ìº¡í•‘)
    for col in required_columns:
        if col != 'Volume':  # Volumeì€ 0ì´ ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì œì™¸
            upper_bound = df_clean[col].quantile(0.995)
            lower_bound = df_clean[col].quantile(0.005)
            df_clean[col] = df_clean[col].clip(lower=lower_bound, upper=upper_bound)
    
    # Volumeì´ 0ì¸ ê²½ìš° ì²˜ë¦¬
    if 'Volume' in required_columns:
        df_clean['Volume'] = df_clean['Volume'].replace(0, df_clean['Volume'].median())
    
    return df_clean

def calculate_returns(df: pd.DataFrame, price_col: str = 'Close') -> pd.Series:
    """ìˆ˜ìµë¥  ê³„ì‚°"""
    return df[price_col].pct_change().fillna(0)

def calculate_volatility(returns: pd.Series, window: int = 20) -> pd.Series:
    """ë³€ë™ì„± ê³„ì‚°"""
    return returns.rolling(window=window).std()

def format_performance_metrics(metrics: dict) -> str:
    """ì„±ê³¼ ì§€í‘œ í¬ë§·íŒ…"""
    formatted = []
    for key, value in metrics.items():
        if isinstance(value, float):
            if 'ratio' in key.lower() or 'sharpe' in key.lower():
                formatted.append(f"**{key}**: {value:.4f}")
            elif 'return' in key.lower():
                formatted.append(f"**{key}**: {value:.2%}")
            else:
                formatted.append(f"**{key}**: {value:.4f}")
        else:
            formatted.append(f"**{key}**: {value}")
    return "\n".join(formatted)

def safe_division(numerator: Union[float, np.ndarray], denominator: Union[float, np.ndarray], default: float = 0.0) -> Union[float, np.ndarray]:
    """ì•ˆì „í•œ ë‚˜ëˆ—ì…ˆ (0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€)"""
    if isinstance(denominator, (int, float)):
        return numerator / denominator if denominator != 0 else default
    else:
        return np.where(denominator != 0, numerator / denominator, default)

def create_date_range(start_date: str, end_date: str) -> Tuple[pd.Timestamp, pd.Timestamp]:
    """ë‚ ì§œ ë²”ìœ„ ìƒì„± ë° ê²€ì¦"""
    try:
        start = pd.to_datetime(start_date)
        end = pd.to_datetime(end_date)
        
        if start >= end:
            raise ValueError("ì‹œì‘ì¼ì´ ì¢…ë£Œì¼ë³´ë‹¤ ëŠ¦ìŠµë‹ˆë‹¤.")
        
        if end > pd.Timestamp.now():
            st.warning("ì¢…ë£Œì¼ì´ í˜„ì¬ ë‚ ì§œë³´ë‹¤ ë¯¸ë˜ì…ë‹ˆë‹¤. í˜„ì¬ ë‚ ì§œë¡œ ì¡°ì •í•©ë‹ˆë‹¤.")
            end = pd.Timestamp.now()
        
        return start, end
    except Exception as e:
        st.error(f"ë‚ ì§œ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤: {e}")
        raise

def show_dataframe_info(df: pd.DataFrame, title: str = "ë°ì´í„° ì •ë³´"):
    """ë°ì´í„°í”„ë ˆì„ ì •ë³´ í‘œì‹œ"""
    with st.expander(f"ğŸ“Š {title}", expanded=False):
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.metric("ë°ì´í„° ìˆ˜", len(df))
        
        with col2:
            st.metric("ì‹œì‘ì¼", df.index.min().strftime('%Y-%m-%d'))
        
        with col3:
            st.metric("ì¢…ë£Œì¼", df.index.max().strftime('%Y-%m-%d'))
        
        st.dataframe(df.describe(), use_container_width=True)

def display_error_with_suggestions(error_msg: str, suggestions: List[str] = None):
    """ì—ëŸ¬ ë©”ì‹œì§€ì™€ í•´ê²° ë°©ì•ˆ í‘œì‹œ"""
    st.error(error_msg)
    
    if suggestions:
        with st.expander("ğŸ’¡ í•´ê²° ë°©ì•ˆ", expanded=True):
            for i, suggestion in enumerate(suggestions, 1):
                st.write(f"{i}. {suggestion}")

def cache_key_generator(*args) -> str:
    """ìºì‹œ í‚¤ ìƒì„±"""
    return "_".join(str(arg) for arg in args)

@st.cache_data(ttl=3600)  # 1ì‹œê°„ ìºì‹œ
def cached_calculation(func, *args, **kwargs):
    """ê³„ì‚° ê²°ê³¼ ìºì‹±"""
    return func(*args, **kwargs)